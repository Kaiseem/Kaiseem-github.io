<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- modified to  your name  -->
    <title>Kai Yao</title>

    <meta name="author" content="Kai Yao">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/tab_icon.png">
</head>

<script type="text/javascript">
  function visibility_on(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'none')
           e.style.display = 'block';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'none')
           e.style.display = 'block';
  }
  function visibility_off(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'block')
           e.style.display = 'none';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'block')
           e.style.display = 'none';
  }
  function toggle_visibility(id) {
      var e = document.getElementById(id+"_text");
      if(e.style.display == 'inline')
         e.style.display = 'block';
      else
         e.style.display = 'inline';
      var e = document.getElementById(id+"_img");
      if(e.style.display == 'inline')
         e.style.display = 'block';
      else
         e.style.display = 'inline';
  }
  function toggle_vis(id) {
      var e = document.getElementById(id);
      if (e.style.display == 'none')
          e.style.display = 'inline';
      else
          e.style.display = 'none';
  }

</script>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Kai Yao 姚 凯</name>
                            </p>
                        <p style="text-align:center">
                            Kai dot Yao at liverpool dot ac dot uk
                        </p>
                        <p> I am a Ph.D. student (2019.12-2023.12) advised by Prof. <a
                                href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a> and Prof. <a
                                href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie
                            Sun</a> at <a
                                href="https://www.liverpool.ac.uk">University of Liverpool</a>. I'm bachelor-straight-to-doctorate student and got full scholarship.
                          My research background lies in computer vision and machine learning.
                        </p>
                        <p>
                            <i>
                                <!-- Here is my quote. -->
                                <!-- Specifically, I am interested in building machine learning algorithms for visual tasks with minimum human supervision. -->
                            </i>
                        </p>
                        I have been working on some research topics including unsupervised learning, domain
                        generalization,
                        domain adaptation, and image generation. Previously, I completed B.Eng. at Xi'an
                        Jiaotong-Liverpool University.
                        <p style="text-align:center">
                            <a href="data/CV.pdf">English CV</a> &nbsp/&nbsp
                            <a href="data/CV_CN.pdf">Chinese CV</a> &nbsp/&nbsp
                            <a href="https://scholar.google.com/citations?hl=en&user=pnsLGLMAAAAJ">Google Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://github.com/Kaiseem/">Github</a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <img style="width:100%;max-width:100%" alt="profile photo" src="images/kaiyao.jpg">
                    </td>
                </tr>
                </tbody>
            </table>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                    <td>
                        <heading>News</heading>
                        <ul>
                            <li>May 2023 - Our two journal papers accepted in IEEE TETCI and IJB.
                            </li>
                            <li>Apr 2023 - Our two journal papers accepted. Meanwhile, I am starting a new open source project <a
                                    href="https://github.com/Kaiseem/sd-webui-imageguard">ImageGuard</a>.
                            </li>
                            <li>Jan 2023 - We release the code for <a
                                    href="https://github.com/Kaiseem/AD-GAN">AD-GAN</a>, under review.
                            </li>
                            <li>Nov 2022 - Our conference paper accepted in AAAI'23. We propose a novel augmentation for
                                medical image domain generalization.
                                The code released at <a href="https://github.com/Kaiseem/SLAug">here</a>.
                            </li>
                            <li>Jul 2022 - Our conference paper accepted in ECCV'22. We propose a novel hybrid
                                vision-transformer-based GAN for image outpainting.
                                The code released at <a href="https://github.com/Kaiseem/QueryOTR">here</a>.
                            </li>

                            <li><a href="javascript:toggle_vis('news')">show more</a></li>
                            <div id="news" style="display:none">
                                                            <li>Jun 2022 - Our journal paper accepted in IEEE-JBHI (IF: 7.0).</li>
                            <li>Dec 2021 - Our team PremiLab wins 5th in the Challenge <a
                                    href="https://www.sciencedirect.com/science/article/pii/S1361841522002560">CrossMoDa
                                2021 (MICCAI workshop)</a>.
                            </li>
                                <li>Dec 2021 - Our journal paper accepted in International Journal of Bioprinting (IF:
                                    7.4).
                                </li>
                                <li>Nov 2021 - Our journal paper accepted in Cognitive Computation (IF: 4.9).</li>
                              <li>Dec 2019 - I started my PhD course at UoL PremiLab Lab with full scholarship.</li>
                            </div>
                        </ul>
                    </td>
                </tr>

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                            <heading>Publication</heading>
                            <p>
                            Sort by publication time. First author papers are <span class="highlight">highlighted</span>.
                            </p>
                        </td>
                    </tr>
                    </tbody>
                </table>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>

               <!----------------------------------- review1 (IJB23) ------------------------------------------------->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div>
                                    <img src='images/ijb23_1.png' width="160">
                            </div>

                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://ijb.whioce.com/index.php/int-j-bioprinting/article/view/717">
                                <papertitle>Machine learning and 3D bioprinting
                                </papertitle>
                            </a>
                            <br>
                            <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>,
                            <strong>Kai Yao</strong>,
                            Jia An,
                            Linzhi Jing,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>,
                            <a href="https://scholar.google.com/citations?hl=zh-CN&user=EKdoAtgAAAAJ">Dejian Huang</a>
                            <br>
                            <em>International Journal of Bioprinting (IJB)</em>, 2023

                            <p></p>
                            <p>
                                A review paper summarize past works and reveal the current challenging towards bioprinting.
                            </p>
                        </td>
                    </tr>


                    <!----------------------------------- TETCI 23 ------------------------------------------------->
                    <tr onmouseout="pun_stop()" onmouseover="pun_start()"   bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <div class="two" id='pun_image'>
                                    <img src='images/arxiv_pointnunet_after.png' width="160"></div>
                                <img src='images/arxiv_pointnunet.png' width="160">
                            </div>
                            <script type="text/javascript">
                function pun_start() {
                  document.getElementById('pun_image').style.opacity = "1";
                }
                function pun_stop() {
                  document.getElementById('pun_image').style.opacity = "0";
                }
                pun_stop()

                            </script>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/pdf/2111.01557.pdf">
                                <papertitle>PointNu-Net: Simultaneous Multi-tissue Histology Nuclei Segmentation and
                                    Classification in the Clinical Wild
                                </papertitle>
                            </a>
                            <br>
                            <strong>Kai Yao</strong>,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>,
                            <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>,
                            Amir Hussain,
                            Curran Jude
                            <br>
                            <em>IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI)</em>, 2023
                            <p></p>
                            <p>
                                In this study, we proposed a novel keypoint-aware method to to simultaneously detect,
                                segment, and classify nuclei from Haematoxylin and Eosin (H&E) stained histopathology
                                data.
                            </p>
                        </td>
                    </tr>

               <!----------------------------------- GAP (JBHI'23) ------------------------------------------------->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">

                                    <img src='images/jbhi23_gap.png' width="160">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2205.11888">
                                <papertitle>Mind The Gap: Alleviating Local Imbalance for Unsupervised Cross-Modality Medical Image Segmentation
                                </papertitle>
                            </a>
                            <br>
                            <a href="https://scholar.google.com/citations?user=E-Mcb5AAAAAJ">Zixian Su</a>,
                            <strong>Kai Yao</strong>,
                            <a href="https://www.xjtlu.edu.cn/en/departments/academic-departments/intelligent-science/staff/xi-yang01">Xi Yang</a>,
                            Qiufeng Wang,
                            Yuyao Yan,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>,
                            <br>
                            <em>IEEE Journal of Biomedical and Health Informatics (JBHI)</em>, 2023

                            <p></p>
                            <p>
                                We propose a novel strategy to alleviate the domain gap imbalance considering the characteristics of medical images, namely Global-Local Union Alignment.
                            </p>
                        </td>
                    </tr>

                    <!----------------------------------- Processes 23 ------------------------------------------------->
                    <tr">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">

                                    <img src='images/process_23.png' width="160">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://www.mdpi.com/2227-9717/11/4/1003">
                                <papertitle>Machine Learning Methods in Skin Disease Recognition: A Systematic Review</papertitle>
                            </a>
                            <br>
                            <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>,
                            <strong>Kai Yao</strong>,
                            Guangyao Huang,
                            Chengrui Zhang,
                            Mark Leach,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>,
                            Xi Yang
                            <br>
                            <em>Processes</em>, 2023
                            <p></p>
                            <p>
                                This paper overviews the status and progress of ML applications for skin disease recognition.
                            </p>
                        </td>
                    </tr>


                    <!----------------------------------- SLAug (AAAI'23) ------------------------------------------------->
                    <tr onmouseout="slaug_stop()" onmouseover="slaug_start()" bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <div class="two" id='slaug_image'>
                                    <img src='images/aaai23_slaug_after.png' width="160"></div>
                                <img src='images/aaai23_slaug.png' width="160">
                            </div>
                            <script type="text/javascript">
                function slaug_start() {
                  document.getElementById('slaug_image').style.opacity = "1";
                }
                function slaug_stop() {
                  document.getElementById('slaug_image').style.opacity = "0";
                }
                slaug_stop()

                            </script>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2211.14805">
                                <papertitle>Rethinking Data Augmentation for Single-source Domain Generalization in
                                    Medical Image Segmentation
                                </papertitle>
                            </a>
                            <br>

                            <a href="https://scholar.google.com/citations?user=E-Mcb5AAAAAJ">Zixian Su*</a>,
                            <strong>Kai Yao*</strong>,
                            <a href="https://www.xjtlu.edu.cn/en/departments/academic-departments/intelligent-science/staff/xi-yang01">Xi Yang</a>,
                            <a href="http://www.premilab.com/QiufengWANG.ashx">Qiufeng Wang</a>,
                            <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>
                            <br>
                            (*equal contribution)
                            <br>
                            <em>Association for the Advancement of Artificial Intelligence (AAAI)</em>, 2023
                            <br>
                            <a href="pdfs/aaai2023_posters.pdf">poster</a>
                            /
                            <a href="https://arxiv.org/pdf/2211.14805.pdf">arXiv</a>
                            /
                            <a href="https://github.com/Kaiseem/SLAug">GitHub</a>
                            <p></p>
                            <p>
                                We design a novel augmentation for medical image domain generalization and theoretically
                                prove that our proposed augmentation can lead to an upper bound of the generalization
                                risk on the unseen target domain.
                            </p>
                        </td>
                    </tr>

                    <!----------------------------------- QueryOTR (ECCV'22) ------------------------------------------------->
                    <tr onmouseout="queryotr_stop()" onmouseover="queryotr_start()"   bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <div class="two" id='queryotr_image'>
                                    <img src='images/eccv22_queryotr_after.png' width="160"></div>
                                <img src='images/eccv22_queryotr.png' width="160">
                            </div>
                            <script type="text/javascript">
                function queryotr_start() {
                  document.getElementById('queryotr_image').style.opacity = "1";
                }
                function queryotr_stop() {
                  document.getElementById('queryotr_image').style.opacity = "0";
                }
                queryotr_stop()

                            </script>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://link.springer.com/chapter/10.1007/978-3-031-20050-2_10">
                                <papertitle>Outpainting by Queries</papertitle>
                            </a>
                            <br>
                            <strong>Kai Yao*</strong>,
                            <a href="https://scholar.google.com/citations?user=yYtjWX0AAAAJ">Penglei Gao*</a>,
                            <a href="https://www.xjtlu.edu.cn/en/departments/academic-departments/intelligent-science/staff/xi-yang01">Xi Yang</a>,
                            <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>,
                            Rui Zhang,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>
                            <br>
                            (*equal contribution)
                            <br>
                            <em>European Conference on Computer Vision (ECCV)</em>, 2022
                            <br>
                            <a href="pdfs/eccv22_posters.pdf">poster</a>
                            /
                            <a href="https://arxiv.org/pdf/2207.05312.pdf">arXiv</a>
                            /
                            <a href="https://github.com/Kaiseem/QueryOTR">GitHub</a>
                            <p></p>
                            <p>
                                we propose a novel hybrid vision-transformer-based encoder-decoder framework, named
                                Query Outpainting TRansformer (QueryOTR), for extrapolating visual context all-side
                                around a given image.
                            </p>
                        </td>
                    </tr>

                    <!----------------------------------- DAR-UNet (JBHI'22) ------------------------------------------------->
                    <tr onmouseout="daru_stop()" onmouseover="daru_start()"   bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <div class="two" id='daru_image'>
                                    <img src='images/jbhi22_darunet_after.png' width="160"></div>
                                <img src='images/jbhi22_darunet.png' width="160">
                            </div>
                            <script type="text/javascript">
                function daru_start() {
                  document.getElementById('daru_image').style.opacity = "1";
                }
                function daru_stop() {
                  document.getElementById('daru_image').style.opacity = "0";
                }
                daru_stop()

                            </script>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://ieeexplore.ieee.org/abstract/document/9741336">
                                <papertitle>A novel 3D unsupervised domain adaptation framework for cross-modality
                                    medical image segmentation
                                </papertitle>
                            </a>
                            <br>
                            <strong>Kai Yao*</strong>,
                            <a href="https://scholar.google.com/citations?user=E-Mcb5AAAAAJ">Zixian Su*</a>,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>,
                            <a href="https://www.xjtlu.edu.cn/en/departments/academic-departments/intelligent-science/staff/xi-yang01">Xi Yang</a>,
                            <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>,
                            Amir Hussain,
                            Frans Coenen
                            <br>
                            (*equal contribution)
                            <br>
                            <em>IEEE Journal of Biomedical and Health Informatics (JBHI)</em>, 2022
                            <br>
                            <a href="https://github.com/Kaiseem/DAR-UNet">GitHub</a>
                            <p></p>
                            <p>
                                We proposed a novel GAN for diverse style transfer, and a 3D Dual Attention Residual
                                U-Net for robust and reliable cross-modality semantic segmentation.
                            </p>
                        </td>
                    </tr>


                    <!----------------------------------- MP 22 ------------------------------------------------->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                    <img src='images/materialstoday.png' width="160">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://www.sciencedirect.com/science/article/pii/S2214785322057170">
                                <papertitle>Machine learning applications in scaffold based bioprinting</papertitle>
                            </a>
                            <br>
                            <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>,
                            <strong>Kai Yao</strong>,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>,
                            <a href="https://scholar.google.com/citations?hl=zh-CN&user=EKdoAtgAAAAJ">Dejian Huang</a>,
                            <br>
                            <em>Materials Today: Proceedings</em>, 2022
                            <p></p>
                            <p>
                                This paper overviews the status and progress of ML applications from several aspects:
                                parameter optimization in the fabrication model, in situ monitoring and control,
                                scaffold performance evaluation, and material design.
                            </p>
                        </td>
                    </tr>




                    <!----------------------------------- IJB 21 ------------------------------------------------->
                    <tr onmouseout="ana_stop()" onmouseover="ana_start()"   bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <div class="two" id='ana_image'>
                                    <img src='images/IJB21_adgan_after.png' width="160"></div>
                                <img src='images/IJB21_adgan.png' width="160">
                            </div>
                            <script type="text/javascript">
                function ana_start() {
                  document.getElementById('ana_image').style.opacity = "1";
                }
                function ana_stop() {
                  document.getElementById('ana_image').style.opacity = "0";
                }
                ana_stop()

                            </script>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8852265">
                                <papertitle>Analyzing cell-scaffold interaction through unsupervised 3d nuclei
                                    segmentation
                                </papertitle>
                            </a>
                            <br>
                            <strong>Kai Yao</strong>,
                            <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>,
                            Lingzhi Jing,
                            <a href="https://scholar.google.com/citations?user=DC9Ytm4AAAAJ">Hang Liu</a>,
                            <a href="https://scholar.google.com/citations?hl=zh-CN&user=EKdoAtgAAAAJ">Dejian Huang</a>,
                            Curran Jude
                            <br>
                            <em>International Journal of Bioprinting</em>, 2021
                            <p></p>
                            <p>
                                Taking advantages of AD-GAN, in this paper, we study with cell-scaffold interaction.
                            </p>
                        </td>
                    </tr>

                    <!----------------------------------- arxiv 21 ------------------------------------------------->
                    <tr onmouseout="adgan_stop()" onmouseover="adgan_start()"   bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <div class="two" id='adgan_image'>
                                    <img src='images/arxiv_adgan_after.png' width="160"></div>
                                <img src='images/arxiv_adgan.png' width="160">
                            </div>
                            <script type="text/javascript">
                function adgan_start() {
                  document.getElementById('adgan_image').style.opacity = "1";
                }
                function adgan_stop() {
                  document.getElementById('adgan_image').style.opacity = "0";
                }
                adgan_stop()

                            </script>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/pdf/2107.11022.pdf">
                                <papertitle>AD-GAN: End-to-end unsupervised nuclei segmentation with aligned
                                    disentangling training
                                </papertitle>
                            </a>
                            <br>
                            <strong>Kai Yao</strong>,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>,
                            <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>,
                            Curran Jude
                            <br>
                            <em>Preprint, under review.</em>, 2021
                            <p></p>
                            <p>
                                We developed herein an end-to-end model called Aligned Disentangled Generative
                                Adversarial Network (AD-GAN) for 3D unsupervised nuclei segmentation of CLSM images.
                            </p>
                        </td>
                    </tr>


                    <!----------------------------------- IJB 21 ------------------------------------------------->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div>
                                    <img src='images/ijb21_1.png' width="160">

                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8852265">
                                <papertitle>Electrohydrodynamic jet-printed ultrathin polycaprolactone scaffolds
                                    mimicking bruch’s membrane for retinal pigment epithelial tissue engineering
                                </papertitle>
                            </a>
                            <br>
                            <a href="https://scholar.google.com/citations?user=DC9Ytm4AAAAJ">Hang Liu</a>, Fan Wu, Renwei Chen, Yanan Chen, <strong>Kai Yao</strong>, Zengping Liu, Bhav
                            Harshad Parikh, Linzhi Jing, Tiange Liu, Xinyi Su, <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>, <a href="https://scholar.google.com/citations?hl=zh-CN&user=EKdoAtgAAAAJ">Dejian Huang</a>
                            <br>
                            <em>International Journal of Bioprinting</em>, 2021
                            <p></p>
                            <p>
                                The purpose of this work is to build and evaluate the performance of ultrathin scaffolds
                                with an electrohydrodynamic jet (EHDJ) printing method for RPE cell culture.
                            </p>
                        </td>
                    </tr>

                    <!----------------------------------- CC21 ------------------------------------------------->
                    <tr onmouseout="a549_stop()" onmouseover="a549_start()"   bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                <div class="two" id='a549_image'>
                                    <img src='images/scaffoda549.png' width="160"></div>
                                <img src='images/scaffoda549.png' width="160">
                            </div>
                            <script type="text/javascript">
                function a549_start() {
                  document.getElementById('a549_image').style.opacity = "1";
                }
                function a549_stop() {
                  document.getElementById('a549_image').style.opacity = "0";
                }
                a549_stop()

                            </script>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8852265">
                                <papertitle>Scaffold-A549: a benchmark 3D fluorescence image dataset for unsupervised
                                    nuclei segmentation
                                </papertitle>
                            </a>
                            <br>
                            <strong>Kai Yao</strong>,
                            <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>,
                            <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>,
                            Lingzhi Jing,
                            <a href="https://scholar.google.com/citations?hl=zh-CN&user=EKdoAtgAAAAJ">Dejian Huang</a>,
                            Curran Jude
                            <br>
                            <em>Cognitive Computation</em>, 2021
                            <br>
                            <a href="https://github.com/Kaiseem/Scaffold-A549">GitHub</a>
                            <p></p>
                            <p>
                                In this paper, we introduce a new benchmark nuclei segmentation dataset termed as
                                Scaffold-A549 for 3D cell culture on bio-scaffold.
                            </p>
                        </td>
                    </tr>


                    <!----------------------------------- ACS Applied Bio Materials21 ------------------------------------------------->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div>
                                    <img src='images/abridgeofcar.jpg' width="160">

                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://pubs.acs.org/doi/abs/10.1021/acsabm.0c01587">
                                <papertitle>Noninvasive In Vivo Imaging and Monitoring of 3D-Printed Polycaprolactone
                                    Scaffolds Labeled with an NIR Region II Fluorescent Dye
                                </papertitle>
                            </a>
                            <br>
                            Lingzhi Jing,Mingtai Sun, Pingkang Xu, <strong>Kai Yao</strong>, Jiao Yang, Xiang Wang, Hang
                            Liu, Minxuan Sun, Yao Sun, Runyan Ni, <a href="https://www.xjtlu.edu.cn/zh/departments/academic-departments/industrial-design/staff/jie-sun">Jie Sun</a>, <a href="https://scholar.google.com/citations?hl=zh-CN&user=EKdoAtgAAAAJ">Dejian Huang</a>
                            <br>
                            <em>ACS Applied Bio Materials</em>, 2021
                            <p></p>
                            <p>
                                In this paper, I mainly contribute to the visualization.
                            </p>
                        </td>
                    </tr>

                    <!----------------------------------- Neurocomputing 20 ------------------------------------------------->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div>

                                    <img src='images/ksminmax.png' width="160">
                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://www.sciencedirect.com/science/article/pii/S0925231220303313">
                                <papertitle>Improving deep neural network performance by integrating kernelized Min-Max
                                    objective
                                </papertitle>
                            </a>
                            <br>
                            <a href="http://www.premilab.com/QiufengWANG.ashx">Qiufeng Wang</a>, <strong>Kai Yao</strong>, Rui Zhang, Amir Hussain, Kaizhu Huang
                            <br>
                            <em>Neurocomputing</em>, 2020
                            <p></p>
                            <p>
                                In this paper, we propose to integrate a kernelized Min-Max objective in the DNN
                                training in order to explicitly enforce both kernelized within-class compactness and
                                between-class margin.
                            </p>
                        </td>
                    </tr>


                    <!----------------------------------- ICONIP18 ------------------------------------------------->
                    <tr bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div>

                                    <img src='images/ksminmax.png' width="160">

                            </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://link.springer.com/chapter/10.1007/978-3-030-04167-0_17">
                                <papertitle>Improving Deep Neural Network Performance with Kernelized Min-Max
                                    Objective
                                </papertitle>
                            </a>
                            <br>
                            <strong>Kai Yao</strong>, <a href="http://www.premilab.com/KaizhuHUANG.ashx">Kaizhu Huang</a>, Rui Zhang, Amir Hussain
                            <br>
                            <em>International Conference on Neural Information Processing (ICONIP)</em>, 2018
                            <p></p>
                            <p>
                                In this paper, we propose to integrate a kernelized Min-Max objective in the DNN
                                training in order to explicitly enforce both kernelized within-class compactness and
                                between-class margin.
                            </p>
                        </td>
                    </tr>

                    </tbody>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                    <tr>
                        <td>
                            <br>
                            <p align="right"><font size="2">
                                <a href="https://people.eecs.berkeley.edu/~barron/">Thanks to the source code from this
                                    guy.</a>
                            </font>
                            </p>
                        </td>
                    </tr>
                    </tbody>
                </table>
                </td>
                </tr>
            </table>
</html>
